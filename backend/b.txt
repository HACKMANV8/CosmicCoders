# naivebayes.py
import pandas as pd
from collections import defaultdict
import math
from fastapi import APIRouter, Request

router = APIRouter()

@router.post("/naivebayes")
async def naive_bayes(request: Request):
    body = await request.json()
    dataset_id = body.get("dataset_id")
    params = body.get("params", {})
    target = params.get("target")
    example = params.get("example", {})

    # Load dataset (replace with actual dataset path)
    df = pd.read_csv("flu_dataset.csv")

    if target not in df.columns:
        return {"error": "Invalid target column"}

    # Preview few rows
    dataset_preview = df.head(5).to_dict(orient="records")

    # --- Step 1: Prior Probabilities ---
    priors = df[target].value_counts(normalize=True).to_dict()
    step1 = {
        "step": 1,
        "title": "Compute Prior Probabilities",
        "result": {"priors": priors},
        "description": "Calculate class priors P(Class) = count(Class)/N"
    }

    # --- Step 2: Conditional Probabilities ---
    likelihoods = defaultdict(dict)
    for feature in df.columns:
        if feature == target:
            continue
        for cls in df[target].unique():
            subset = df[df[target] == cls]
            probs = subset[feature].value_counts(normalize=True).to_dict()
            likelihoods[cls][feature] = probs

    step2 = {
        "step": 2,
        "title": "Compute Conditional Probabilities",
        "result": {"details": likelihoods},
        "description": "For each class and feature, compute P(Feature|Class)"
    }

    # --- Step 3: Compute Unnormalized Posteriors ---
    per_class = {}
    for cls in df[target].unique():
        prior = priors[cls]
        multipliers = []
        prob = prior
        for feature, value in example.items():
            cond_probs = likelihoods[cls].get(feature, {})
            p = cond_probs.get(value, 1e-6)  # Laplace smoothing
            prob *= p
            multipliers.append({"feature": feature, "value": value, "p": round(p, 6)})
        per_class[cls] = {
            "unnormalized": round(prob, 8),
            "multipliers": multipliers
        }

    step3 = {
        "step": 3,
        "title": "Calculate Unnormalized Posterior",
        "result": {"per_class": per_class},
        "description": "Multiply priors and conditional probabilities for each class"
    }

    # --- Step 4: Normalize ---
    total = sum([v["unnormalized"] for v in per_class.values()])
    posteriors = {cls: v["unnormalized"] / total for cls, v in per_class.items()}
    step4 = {
        "step": 4,
        "title": "Normalize to Get Posterior Probabilities",
        "vars": {"evidence": total},
        "result": {"posteriors": posteriors},
        "description": "Normalize so that all class probabilities sum to 1"
    }

    # --- Step 5: Final Prediction ---
    predicted = max(posteriors, key=posteriors.get)
    confidence = posteriors[predicted]
    step5 = {
        "step": 5,
        "title": "Make Final Prediction",
        "result": {"predicted": predicted, "confidence": confidence},
        "description": "Choose the class with the highest posterior probability"
    }

    return {
        "dataset_preview": dataset_preview,
        "steps": [step1, step2, step3, step4, step5]
    }
